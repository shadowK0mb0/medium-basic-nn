{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will try and import just base libraries so you can see from which package the different functions come from\n",
    "import torch\n",
    "import torchvision\n",
    "import typing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The easy way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out, the fashion mnist dataset is directly available from the torchvision.datasets library! The easiest way to load the dataset would be taking advantage of that library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    target_transform=torchvision.transforms.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)),\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    target_transform=torchvision.transforms.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, not every dataset will be available through a library. In that case, you will have to download the dataset yourself, and create your OWN dataset class that handles the data. Let's take a look at how to do that below. Running the cells above would have downloaded the data into a new folder called data, which we'll parse manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Hard Way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's use the gzip library to convert the files downloaded previously into numpy arrays. If you haven't run the cells above, please do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:  (60000, 1, 28, 28)\n",
      "test data shape:  (10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 1, 28, 28)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "X_train, y_train = load_mnist('data/FashionMNIST/raw/', kind='train')\n",
    "X_test, y_test = load_mnist('data/FashionMNIST/raw/', kind='t10k')\n",
    "\n",
    "print('train data shape: ', X_train.shape)\n",
    "print('test data shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as you can get you data to numpy arrays, you are good to go! When dealing with data such as text, there is a special step called [tokenization](https://huggingface.co/docs/transformers/tokenizer_summary) which you have to do first. However, that is much more advanced and beyond the scope of this tutorial.\n",
    "\n",
    "Now we will create a pytorch dataset class using the numpy arrays we created. When passing input to pytorch models, these models always work with pytorch tensors and not any other type of matrices. This means we will have to build torch tensors (via `torch.Tensor(...)` and `torch.LongTensor`) from each of our numpy arrays. Notice when using the torchvision dataset we pass in a transform `torchvision.transforms.ToTensor()`. That automatically handles converting our matrix to `torch.Tensor` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g9/294r07312xs27rdfv4kz7zpm0000gn/T/ipykernel_10243/3062027500.py:13: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1666646603923/work/torch/csrc/utils/tensor_numpy.cpp:205.)\n",
      "  training_data = CustomFashinMNSITDataset(torch.Tensor(X_train), torch.LongTensor(y_train))\n"
     ]
    }
   ],
   "source": [
    "# it is important our custom class subclasses the Dataset class\n",
    "class CustomFashinMNSITDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X: torch.Tensor, y: torch.Tensor) -> None:\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index: int) -> typing.Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.X[index], torch.zeros(10, dtype=torch.float).scatter_(0, self.y[index], value=1)\n",
    "\n",
    "training_data = CustomFashinMNSITDataset(torch.Tensor(X_train), torch.LongTensor(y_train))\n",
    "test_data = CustomFashinMNSITDataset(torch.Tensor(X_test), torch.LongTensor(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless of how we create the dataset, we now have a Dataset object. Using this we create a data loader class. This will handle iterating over \"batches\" (small chunks of the dataset) to train our model. We could loop over each individual data point one by one, but people have found that training in **batches** tends to be more effective. Essentially, we take a batch of say 64 random examples left in our dataset, compute the predictions for them, and then edit the weights using all 64 predictions. This helps the model to **generalize** to new data. One example at a time (batch size of 1) would make very extreme changes as one example is not very representative of the dataset. It would also be incredibly ineffecient. Lots of example is quite efficient, but does not give the model to learn as much from each mistake, it is sort of recieving feedback on a project all at once vs little by little in digestable chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quickly look at a the size of our first batch, and the very first image in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64, 10])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our label tensor is not just a value in [0,9]. It is an array of 0's, with a 1 at the INDEX of the label. This is because rather than have a single output predict one continuous value that is between 0 and 10, we can have ten output nodes each predict one class. More concretely, these are the labels for fashion mnist:\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |\n",
    "\n",
    "However, can we add 1 to trouser to get pullover? Can we subtract 3 from sandal and get dress? No, although a single continuous label value might make more sense in our minds, the continuity of the label space has relationships that we DON'T want. So by splitting it up into 10 different labels, we can avoid this implicity relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's plenty of talking about datasets, let's get on to building the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we can build our model in a super simple and quick way, or a much more tedious version. As usual, the simple way does not offer as much flexibility as the hard way but is still useful to know of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Easy Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(28 * 28, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(512, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(512, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty straight forward implementation. This `torch.nn.Sequential` is a wrapper that forward the input through each layer in the order you pass them in. In our case, the model will first flatten the input, then pass it through a linear layer that changes the last dimension from 28*28 to 512, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tedious Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMnistClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionMnistClassifier, self).__init__()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear_relu_stack = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28*28, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = FashionMnistClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have done here is placed different layers into instance variables in the `__init__` function. Now, we override the forward function, that given an input vector x, spits out the output. Since we replicating the same behavoir as the easy way, we just pass x through flatten, then pass it through our `linear_rule_stack`. However, defining your own forward function helps for building more complex forward passes. This definitely isn't harder, but it can be more tedious. I would say this is always worth the extra effort though for readability and flexibility. You can notice we actually used `torch.nn.Sequential` inside our class, which is a module like any other. This means we can call module(x) and it will pass x to the forward method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are onto the final step of the model, and here there is no easy way vs other way. There really is just one well defined format we will use to train our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three key elements to training our model:\n",
    "\n",
    "    - Loss Function\n",
    "    - Optimizer\n",
    "    - Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the loss function is pretty easy in pytorch. At a high level, you pass in two arrays, the model's predictions and the ground truths. For each example, you compare the prediction and ground truth and compute some sort of \"loss\" value. Essentially, the higher loss value, the worse your model did. The training process adjusts the weights of the model in order to minimize the loss value, so it is important to make sure you select the correct loss function.\n",
    "\n",
    "While we can also build our own loss function pretty quickly, PyTorch has almost every popular loss function you could think of built into it already. We will use the built in CrossEntropyLoss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the algorithm that will optimize the parameters in our neural network so that our model actually **learns**. These are a lot more complex than loss functions. Optimizers make use of partial derivatives and momentum to optimally minimize the loss function. Partial derivatives help to identify which parameters contributed most to a large loss. At a high level, this informs the optimizer which parameters need to be adjusted and which can be left alone. Momentum helps to avoid settling at local minima and instead settle at global minima. Part of deciding the \"moentum\" portion of an optimizer is the **learning rate**. Too slow of a learning rate and your model will take forever to train and get stuck at local minima. Too high of a learning rate and your model's loss could spiral out of control.\n",
    "\n",
    "We will be using the simple `Stochastic Gradient Descent` (aka SGD) algorithm, but the modern, state of the art optimizer most people use is called `Adam`. It should be noted though that while `Adam` is a great all round optimizer, different optimizers are better suited for different tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After selecting the appropriate loss function and optimizer, we need to iterate over our dataset, and train the model using all the points in the dataset in batches that we defined when we previously created our DataLoader. We also need to define how many times we want to loop over the dataset when we train. It is often more helpful to look over the entire dataset multiple times for the model to better understand it. This is called the number of **epochs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i+1}\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained and tested our model, we can use it to classify our own new examples! Draw your own 28x28 pixel grayscale image, load it, and see what our model says!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load the model for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is best practice to save just the model weights to a file. This ensure that when you recreate the model and load the weights, you have actually recreated the correct model. You can also save the whole model file object and load it, however since this doesn't require you to instantiate the model you may not load the correct model, and have no way of knowing whether you did or not. By instantiating the model first and directly loading the weights you can ensure that the correct model has been created, even if it is a bit more work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model is pretty easy and can be done in a single line. Just get the state dict, and save it with the built in `torch.save` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the weights into a new instance of the same type of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = FashionMnistClassifier()\n",
    "model.load_state_dict(torch.load('model_weights.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you are curious, here is how you would irectly save and load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')\n",
    "# Notice how we have no idea what the model parameters are since it's\n",
    "# inside a file. We can load it into any variable name we want.\n",
    "model3 = torch.load('model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('emo_rec')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25765e9f1aac4ddb0f2c2adc603e5a666152fa7973f48709a8a96c938c1060b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
